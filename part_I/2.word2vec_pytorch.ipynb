{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "random-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.functional as F\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extreme-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'he is a king',\n",
    "    'she is a queen',\n",
    "    'king is a man',\n",
    "    'queen is a woman',\n",
    "    'he is a man',\n",
    "    'she is a woman',\n",
    "    'warsaw is poland capital',\n",
    "    'berlin is germany capital',\n",
    "    'paris is france capital',\n",
    "    'paris is a nice city to visit',\n",
    "    'london is england capital',\n",
    "    'brasilia is brasil capital',\n",
    "    'buenos aires is argentina capital'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stuffed-relationship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he is a king',\n",
       " 'she is a queen',\n",
       " 'king is a man',\n",
       " 'queen is a woman',\n",
       " 'he is a man',\n",
       " 'she is a woman',\n",
       " 'warsaw is poland capital',\n",
       " 'berlin is germany capital',\n",
       " 'paris is france capital',\n",
       " 'paris is a nice city to visit',\n",
       " 'london is england capital',\n",
       " 'brasilia is brasil capital',\n",
       " 'buenos aires is argentina capital']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collectible-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_corpus(corpus):\n",
    "    tokens = [x.split() for x in corpus]\n",
    "    return tokens\n",
    "\n",
    "tokenized_corpus = tokenize_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liable-navigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['he', 'is', 'a', 'king'],\n",
       " ['she', 'is', 'a', 'queen'],\n",
       " ['king', 'is', 'a', 'man'],\n",
       " ['queen', 'is', 'a', 'woman'],\n",
       " ['he', 'is', 'a', 'man'],\n",
       " ['she', 'is', 'a', 'woman'],\n",
       " ['warsaw', 'is', 'poland', 'capital'],\n",
       " ['berlin', 'is', 'germany', 'capital'],\n",
       " ['paris', 'is', 'france', 'capital'],\n",
       " ['paris', 'is', 'a', 'nice', 'city', 'to', 'visit'],\n",
       " ['london', 'is', 'england', 'capital'],\n",
       " ['brasilia', 'is', 'brasil', 'capital'],\n",
       " ['buenos', 'aires', 'is', 'argentina', 'capital']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "greenhouse-guard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he', 'is', 'a', 'king']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "internal-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for sentence in tokenized_corpus:\n",
    "    for token in sentence:\n",
    "        if token not in vocabulary:\n",
    "            vocabulary.append(token)\n",
    "\n",
    "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "superior-wedding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'he': 0,\n",
       " 'is': 1,\n",
       " 'a': 2,\n",
       " 'king': 3,\n",
       " 'she': 4,\n",
       " 'queen': 5,\n",
       " 'man': 6,\n",
       " 'woman': 7,\n",
       " 'warsaw': 8,\n",
       " 'poland': 9,\n",
       " 'capital': 10,\n",
       " 'berlin': 11,\n",
       " 'germany': 12,\n",
       " 'paris': 13,\n",
       " 'france': 14,\n",
       " 'nice': 15,\n",
       " 'city': 16,\n",
       " 'to': 17,\n",
       " 'visit': 18,\n",
       " 'london': 19,\n",
       " 'england': 20,\n",
       " 'brasilia': 21,\n",
       " 'brasil': 22,\n",
       " 'buenos': 23,\n",
       " 'aires': 24,\n",
       " 'argentina': 25}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "diagnostic-canyon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'he',\n",
       " 1: 'is',\n",
       " 2: 'a',\n",
       " 3: 'king',\n",
       " 4: 'she',\n",
       " 5: 'queen',\n",
       " 6: 'man',\n",
       " 7: 'woman',\n",
       " 8: 'warsaw',\n",
       " 9: 'poland',\n",
       " 10: 'capital',\n",
       " 11: 'berlin',\n",
       " 12: 'germany',\n",
       " 13: 'paris',\n",
       " 14: 'france',\n",
       " 15: 'nice',\n",
       " 16: 'city',\n",
       " 17: 'to',\n",
       " 18: 'visit',\n",
       " 19: 'london',\n",
       " 20: 'england',\n",
       " 21: 'brasilia',\n",
       " 22: 'brasil',\n",
       " 23: 'buenos',\n",
       " 24: 'aires',\n",
       " 25: 'argentina'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "partial-accordance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size = len(vocabulary)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "equivalent-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 3\n",
    "idx_pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "useful-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each sentence\n",
    "for sentence in tokenized_corpus:\n",
    "    indices = [word2idx[word] for word in sentence]\n",
    "    # for each word, threated as center word\n",
    "    for center_word_pos in range(len(indices)):\n",
    "        # for each window position\n",
    "        for w in range(-window_size, window_size + 1):\n",
    "            context_word_pos = center_word_pos + w\n",
    "            # make soure not jump out sentence\n",
    "            if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n",
    "                continue\n",
    "            context_word_idx = indices[context_word_pos]\n",
    "            idx_pairs.append((indices[center_word_pos], context_word_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "useful-slovenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 2],\n",
       "       [0, 3],\n",
       "       [1, 0],\n",
       "       [1, 2],\n",
       "       [1, 3],\n",
       "       [2, 0],\n",
       "       [2, 1],\n",
       "       [2, 3],\n",
       "       [3, 0],\n",
       "       [3, 1],\n",
       "       [3, 2],\n",
       "       [4, 1],\n",
       "       [4, 2],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_pairs = np.array(idx_pairs) # it will be useful to have this as numpy array\n",
    "idx_pairs[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-excess",
   "metadata": {},
   "source": [
    "<img src=\"w2v_1.png\" width=\"150\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "filled-pavilion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair - 0 - [0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['he', 'is']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 0\n",
    "print(f\"Pair - {ix} - {idx_pairs[ix]}\")\n",
    "[idx2word[x] for x in idx_pairs[ix]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "diverse-interest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair - 1 - [0 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['he', 'a']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 1\n",
    "print(f\"Pair - {ix} - {idx_pairs[ix]}\")\n",
    "[idx2word[x] for x in idx_pairs[ix]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "significant-character",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair - 2 - [0 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['he', 'king']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 2\n",
    "print(f\"Pair - {ix} - {idx_pairs[ix]}\")\n",
    "[idx2word[x] for x in idx_pairs[ix]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "permanent-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_one_hot(word_idx):\n",
    "    x = torch.zeros(vocabulary_size).float()\n",
    "    x[word_idx] = 1.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "communist-xerox",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_input_one_hot(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sporting-thomas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_input_one_hot(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "official-probe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_input_one_hot(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "civic-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = 10\n",
    "W1 = torch.randn(embedding_dims, vocabulary_size, requires_grad=True).float()\n",
    "W2 = torch.randn(vocabulary_size, embedding_dims, requires_grad=True).float()\n",
    "num_epochs = 500\n",
    "learning_rate = 0.001\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "broke-poland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epo 0: 6.915566307968564\n",
      "Loss at epo 50: 3.9562672475973764\n",
      "Loss at epo 100: 3.308071145415306\n",
      "Loss at epo 150: 2.9743654479583106\n",
      "Loss at epo 200: 2.760923661126031\n",
      "Loss at epo 250: 2.6125941935512755\n",
      "Loss at epo 300: 2.5028090198834736\n",
      "Loss at epo 350: 2.4165219058593115\n",
      "Loss at epo 400: 2.3464569449424744\n",
      "Loss at epo 450: 2.2886743346850076\n"
     ]
    }
   ],
   "source": [
    "for epo in range(num_epochs):\n",
    "    loss_val = 0\n",
    "    for data, target in idx_pairs:\n",
    "        x = get_input_one_hot(data).float()\n",
    "        y_true = torch.from_numpy(np.array([target])).long()\n",
    "        z1 = torch.matmul(W1, x)\n",
    "        z2 = torch.matmul(W2, z1)\n",
    "    \n",
    "        log_softmax = F.log_softmax(z2, dim=0)\n",
    "\n",
    "        loss = F.nll_loss(log_softmax.view(1,-1), y_true)\n",
    "        loss_val += loss.item()\n",
    "        loss.backward()\n",
    "        W1.data -= learning_rate * W1.grad.data\n",
    "        W2.data -= learning_rate * W2.grad.data\n",
    "\n",
    "        W1.grad.data.zero_()\n",
    "        W2.grad.data.zero_()\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Data:   {data}\")\n",
    "            print(f\"Target: {target}\")\n",
    "            #print(f\"Log SoftMax: {log_softmax}\")\n",
    "            print(f\"Arg Max Log SoftMax: {torch.argmax(log_softmax)}\")\n",
    "            print(f\"True Label: {y_true}\")\n",
    "            print(\"-\"*30)\n",
    "    if epo % 50 == 0:    \n",
    "        print(f'Loss at epo {epo}: {loss_val/len(idx_pairs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "mighty-uniform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 26])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sufficient-profile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "supported-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word):\n",
    "    return W1@get_input_one_hot(word2idx[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "nutritional-landing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3280,  2.2264, -0.4459, -0.8265,  0.5568, -0.9928, -1.3922, -0.5202,\n",
       "         0.1527, -0.6687], grad_fn=<MvBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_king = get_embed(\"king\")\n",
    "embed_king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "paperback-punishment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4386,  0.1551,  1.2959, -0.9430, -0.5632, -1.1942, -0.8030, -0.4712,\n",
       "        -1.5649, -2.0273], grad_fn=<MvBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_queen = get_embed(\"queen\")\n",
    "embed_queen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-sculpture",
   "metadata": {},
   "source": [
    "## Compare Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "southeast-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity(dim=0, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "interested-series",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(embed_king, embed_king)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "accompanied-addiction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0209, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(get_embed(\"king\"), get_embed(\"england\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "spoken-criminal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0668, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(get_embed(\"king\"), get_embed(\"argentina\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "proved-validity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9168, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(get_embed(\"king\"), get_embed(\"man\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "powered-latino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7321, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(get_embed(\"king\"), get_embed(\"woman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-beads",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
